{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7ayk7SSChm5"
   },
   "source": [
    "## California Regression Activity \n",
    "\n",
    "### Description\n",
    "\n",
    "Practice linear regressions\n",
    "\n",
    "### Grading\n",
    "\n",
    "For grading purposes, we will clear all outputs from all your cells and then run them all from the top.  Please test your notebook in the same fashion before turning it in.\n",
    "\n",
    "### Submitting Your Solution\n",
    "\n",
    "To submit your notebook, first clear all the cells (this won't matter too much this time, but for larger data sets in the future, it will make the file smaller).  Then use the File->Download As->Notebook to obtain the notebook file.  Finally, submit the notebook file on Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_Uj4Af6C2gF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import sklearn.datasets\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TMV_V10ErN6"
   },
   "source": [
    "## Procedure\n",
    "\n",
    "For this activity, you are going to make an initial guess or hypothesis about which features best represent the California dataset. You are first going to perform a regression of just a subset of the features you choose, then you are going to perform a regression with all of the features.  The steps for performing a linear regression with sciKit learn are as follows: \n",
    " 1. Load Data (Which includes separating the data into X and y)\n",
    " 2.Do some initial visualizations (e.g., scatter plots or visualizations with 2 or 3 features or a feature vs. the target, maybe some histograms).\n",
    " 3. Split data using train_test_split()\n",
    " 4. Create lr object\n",
    " 5. Train the lr model\n",
    " 6. Test the lr model\n",
    " \n",
    "Note: You do NOT need to do final visualizations like when we used simulated data.\n",
    "\n",
    "Compare the results of both models and discuss why you think one performed better than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the California Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing    \n",
    "housing = fetch_california_housing()\n",
    "data = pd.DataFrame(data=housing.data, columns=housing.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvtBcf0dLioo"
   },
   "source": [
    "### Hypothesis\n",
    "\n",
    "What is your hypothesis?\n",
    "\n",
    "Answer: does the number of rooms and house age representaative of the housing market in california. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFISzPn9GiEF"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing    \n",
    "raw = fetch_california_housing()\n",
    "#print(raw.target_names)\n",
    "cali = DataFrame(raw.data, columns=raw.feature_names)\n",
    "#print(cali)\n",
    "\n",
    "\n",
    "#cali.descibe()\n",
    "\n",
    "table=cali.corr()\n",
    "print('correlation',table)\n",
    "\n",
    "\n",
    "#cali['MedHouseVal'] = raw.target\n",
    "#X = cali[['Population', 'AveRooms', 'HouseAge']]\n",
    "#Y = cali['MedHouseVal']\n",
    "X=data[['AveRooms', 'HouseAge']]\n",
    "Y=housing.target\n",
    "\n",
    "cali.head()\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size =0.2)\n",
    "X_train.shape\n",
    "Y_train.shape\n",
    "\n",
    "#Do some initial visualizations (e.g., scatter plots or visualizations with 2 or 3 features \n",
    "#or a feature vs. the target, maybe some histograms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2WmeccIGsLc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create lr object\n",
    "\n",
    "#step 3 -> split data using train/test split \n",
    "mod=LinearRegression()\n",
    "\n",
    "#help(LinearRegression())\n",
    "\n",
    "#Train model\n",
    "\n",
    "mod.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "#Test model \n",
    "#mod.(Y_test,y_hat)\n",
    "\n",
    "y_hat_test=mod.predict(X_test)\n",
    "resid=(Y_test-y_hat_test)\n",
    "mse=1/(len(Y_test))*sum(resid**2)\n",
    "rmse=np.sqrt(mse)\n",
    "print(\"This is the MSE\",mse)\n",
    "print(\"this is the RMSE\",rmse)\n",
    "mod.score(X_test,Y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(cali['HouseAge'],cali['AveBedrms'])\n",
    "plt.xlabel('House Age')\n",
    "plt.ylabel('Average Bedroom Number')\n",
    "plt.title(\"House Age vs Average Bedroom Number \")\n",
    "plt.show()\n",
    "\n",
    "#plt.hist(cali['MedHouseVal'], density=True, bins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniforms = [cali['HouseAge']]\n",
    "plt.hist(uniforms) # .hist() is what gives us a histogram\n",
    "plt.title(\"House Age \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sm0klnWiLvlM"
   },
   "source": [
    "### Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tIVB1qILzVo"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing    \n",
    "raw = fetch_california_housing()\n",
    "#print(raw.target_names)\n",
    "cali = DataFrame(raw.data, columns=raw.feature_names)\n",
    "#print(cali)\n",
    "\n",
    "\n",
    "#Load dataset\n",
    "#step 4 -> create new lr object \n",
    "#x_train, x_test,y_train,y_test = train_test_split(X,Y,test_size =0.2)\n",
    "\n",
    "#MedInc  HouseAge  AveRooms  AveBedrms  Population  \n",
    "\n",
    "#Latitude  Longitude\n",
    "X=data[['MedInc', 'HouseAge','AveRooms','Population','AveOccup','Latitude','Longitude']]\n",
    "Y=housing.target\n",
    "\n",
    "cali.head()\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size =0.2)\n",
    "X_train.shape\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xmrXL_bLz9E"
   },
   "outputs": [],
   "source": [
    "#Create lr object\n",
    "\n",
    "#step 3 -> split data using train/test split \n",
    "mod=LinearRegression()\n",
    "\n",
    "#help(LinearRegression())\n",
    "\n",
    "#Train model\n",
    "\n",
    "mod.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "#Test model \n",
    "#mod.(Y_test,y_hat)\n",
    "\n",
    "y_hat_test=mod.predict(X_test)\n",
    "resid=(Y_test-y_hat_test)\n",
    "mse=1/(len(Y_test))*sum(resid**2)\n",
    "rmse=np.sqrt(mse)\n",
    "print(\"This is the MSE\",mse)\n",
    "print(\"this is the RMSE\",rmse)\n",
    "mod.score(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7-Ea2mdL1S9"
   },
   "source": [
    "### Discussion\n",
    "\n",
    "Which result is better, and why?\n",
    "\n",
    "Answer: The main thing to avoid is multi-colinearity. None of the variables look to be highly corelated. A good MSE value is close to 0. the first model is aboce 1, as well is the RMSE value, it should be close to 0. The seceond model, which includes all the variables is the better model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO3tMFfLgAAcIdO9p72tTeo",
   "collapsed_sections": [],
   "name": "boston_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f8f591c62df419ee7137d10533b2bbd9b5310e464e752dbc1d72b7e3d7395e16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
